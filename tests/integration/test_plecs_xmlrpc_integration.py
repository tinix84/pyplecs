"""
Comprehensive tests for real PLECS XML-RPC functionality.

These tests verify end-to-end functionality of:
- PLECS startup and XML-RPC connection
- Real simulation execution
- Parameter sweeps
- Cache behavior
- File change detection
"""

import pytest
import tempfile
import shutil
import time
import pandas as pd
from pathlib import Path
from unittest.mock import patch, MagicMock
import sys
import os

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

# Import our modules
from pyplecs.plecs_parser import parse_plecs_file
from pyplecs.cache import SimulationCache

# Import the CLI components we want to test
from cli_demo_nomocks import RealPlecsSimulator, SimulationPlan


class TestRealPlecsIntegration:
    """Test suite for real PLECS XML-RPC integration."""
    
    @pytest.fixture
    def model_file(self):
        """Path to test PLECS model."""
        return Path("data/simple_buck.plecs")
    
    @pytest.fixture 
    def temp_cache_dir(self):
        """Temporary cache directory for tests."""
        temp_dir = tempfile.mkdtemp()
        yield Path(temp_dir)
        shutil.rmtree(temp_dir)
    
    @pytest.fixture
    def simulator(self, model_file, temp_cache_dir):
        """Create a simulator instance for testing."""
        # Mock the cache to use temp directory
        with patch('cli_demo_nomocks.SimulationCache') as mock_cache_class:
            mock_cache = MagicMock()
            mock_cache_class.return_value = mock_cache
            
            simulator = RealPlecsSimulator(model_file)
            simulator.cache = mock_cache
            yield simulator
            
            # Cleanup
            try:
                simulator.close()
            except:
                pass
    
    def test_plecs_startup_and_connection(self, model_file):
        """Test that PLECS starts and XML-RPC connection works."""
        simulator = RealPlecsSimulator(model_file)
        
        try:
            # Test startup
            success = simulator.start_plecs_and_connect()
            assert success, "Failed to start PLECS and connect via XML-RPC"
            
            # Verify connection
            assert simulator.server is not None, "XML-RPC server not initialized"
            assert simulator.plecs_app is not None, "PLECS app not initialized"
            
            # Test basic XML-RPC call
            try:
                # Just verify that the server connection is working
                # by accessing the server object (connection was successful)
                assert hasattr(simulator, 'server'), (
                    "XML-RPC server not accessible"
                )
                # If we get here, the connection test passed
            except Exception as e:
                pytest.fail(f"XML-RPC connection test failed: {e}")
                
        finally:
            simulator.close()
    
    def test_parameter_setting_via_xmlrpc(self, simulator, model_file):
        """Test that parameters are correctly set in PLECS via XML-RPC."""
        # Mock successful connection
        simulator.server = MagicMock()
        simulator.plecs_app = MagicMock()
        
        # Test parameters
        test_params = {
            'Vi': 24.0,
            'Lo': 15e-6,
            'Co': 150e-6,
            'fs': 50000.0
        }
        
        # Call parameter setting
        simulator.set_parameters(test_params)
        
        # Verify load_modelvars was called
        simulator.server.load_modelvars.assert_called_once()
        
        # Get the actual parameters passed
        called_params = simulator.server.load_modelvars.call_args[0][0]
        
        # Verify all test parameters were included
        for param, value in test_params.items():
            assert param in called_params, f"Parameter {param} not set"
            assert called_params[param] == value, f"Parameter {param} value incorrect"
    
    def test_simulation_execution_returns_real_data(self, simulator):
        """Test that simulation execution returns real PLECS data."""
        # Configure cache to return None (cache miss) for this test
        simulator.cache.get_cached_result.return_value = None
        
        # Mock PLECS connection and result
        simulator.server = MagicMock()
        simulator.plecs_app = MagicMock()
        
        # Mock realistic PLECS simulation result
        mock_result = {
            'Time': [i * 1e-6 for i in range(1000)],  # 1000 time points
            'Values': [
                [0.5 + 0.1 * i for i in range(1000)],  # Signal 0
                [12.0 + 0.05 * i for i in range(1000)]  # Signal 1
            ]
        }
        simulator.server.run_sim_with_datastream.return_value = mock_result
        
        # Test parameters (different from cache tests to avoid cache hits)
        test_params = {'Vi': 28.0, 'Lo': 18e-6}
        
        # Run simulation
        result = simulator.run_simulation(test_params)
        
        # Verify result structure
        assert 'timeseries' in result, "Missing timeseries data"
        assert 'metadata' in result, "Missing metadata"
        
        # Verify timeseries data
        timeseries = result['timeseries']
        if hasattr(timeseries, 'columns'):  # pandas DataFrame
            assert 'Time' in timeseries.columns, "Missing Time column"
            assert 'Signal_0' in timeseries.columns, "Missing Signal_0"
            assert 'Signal_1' in timeseries.columns, "Missing Signal_1"
            assert len(timeseries) == 1000, "Incorrect number of data points"
        else:  # dict format
            assert 'Time' in timeseries, "Missing Time data"
            assert 'Signal_0' in timeseries, "Missing Signal_0 data"
            assert 'Signal_1' in timeseries, "Missing Signal_1 data"
            assert len(timeseries['Time']) == 1000, "Incorrect time points"
        
        # Verify metadata
        metadata = result['metadata']
        assert metadata['success'] is True, "Simulation marked as failed"
        assert 'simulation_time' in metadata, "Missing simulation time"
        assert 'parameters' in metadata, "Missing parameters in metadata"
    
    def test_parameter_sweep_generation(self, model_file):
        """Test parameter sweep plan generation."""
        # Parse model to get base parameters
        parsed_data = parse_plecs_file(model_file)
        base_params = parsed_data['init_vars']
        
        # Create simulation plan
        sim_plan = SimulationPlan(model_file, base_params)
        
        # Add parameter sweeps
        sim_plan.add_sweep_parameter('Lo', 10e-6, 50e-6, 5)
        sim_plan.add_sweep_parameter('Co', 100e-6, 500e-6, 3)
        
        # Generate simulation points
        sim_points = sim_plan.generate_simulation_points()
        
        # Verify we get the expected number of combinations
        expected_points = 5 * 3  # 5 Lo values Ã— 3 Co values
        assert len(sim_points) == expected_points, f"Expected {expected_points} simulation points, got {len(sim_points)}"
        
        # Verify each point has correct structure
        for i, point in enumerate(sim_points):
            assert 'Lo' in point, f"Point {i} missing Lo parameter"
            assert 'Co' in point, f"Point {i} missing Co parameter"
            assert '_sweep_id' in point, f"Point {i} missing sweep ID"
            
            # Verify Lo values are in range
            assert 10e-6 <= point['Lo'] <= 50e-6, f"Lo value {point['Lo']} out of range"
            
            # Verify Co values are in range  
            assert 100e-6 <= point['Co'] <= 500e-6, f"Co value {point['Co']} out of range"

    def test_cache_identical_simulations(self, simulator):
        """Test that identical simulations use cache instead of re-running."""
        # Mock PLECS connection
        simulator.server = MagicMock()
        simulator.plecs_app = MagicMock()
        
        # Mock cache behavior
        mock_cache = MagicMock()
        simulator.cache = mock_cache
        
        # Test parameters
        test_params = {
            'Vi': 24.0,
            'Lo': 15e-6,
            '_simulation_type': 'real_plecs',
            '_simulation_engine': 'xml_rpc'
        }
        
        # First call - cache miss, should run simulation
        mock_cache.get_cached_result.return_value = None
        mock_result = {
            'Time': [0, 1e-6, 2e-6],
            'Values': [[1, 2, 3], [4, 5, 6]]
        }
        simulator.server.run_sim_with_datastream.return_value = mock_result
        
        result1 = simulator.run_simulation(test_params)
        
        # Verify simulation was run
        simulator.server.run_sim_with_datastream.assert_called_once()
        mock_cache.cache_result.assert_called_once()
        
        # Second call - cache hit, should NOT run simulation
        simulator.server.reset_mock()
        mock_cache.reset_mock()
        
        cached_result = {
            'timeseries': {'Time': [0, 1e-6], 'Signal_0': [1, 2]},
            'metadata': {'cached': True}
        }
        mock_cache.get_cached_result.return_value = cached_result
        
        result2 = simulator.run_simulation(test_params)
        
        # Verify simulation was NOT run again
        simulator.server.run_sim_with_datastream.assert_not_called()
        mock_cache.cache_result.assert_not_called()
        
        # Verify we got cached result
        assert result2 == cached_result, "Did not return cached result"
    
    def test_cache_different_parameters_trigger_new_simulation(self, simulator):
        """Test that different parameters trigger new simulations."""
        # Mock PLECS connection
        simulator.server = MagicMock()
        simulator.plecs_app = MagicMock()
        
        # Mock cache behavior
        mock_cache = MagicMock()
        simulator.cache = mock_cache
        mock_cache.get_cached_result.return_value = None  # Always cache miss
        
        mock_result = {
            'Time': [0, 1e-6, 2e-6],
            'Values': [[1, 2, 3], [4, 5, 6]]
        }
        simulator.server.run_sim_with_datastream.return_value = mock_result
        
        # First simulation
        params1 = {'Vi': 24.0, 'Lo': 15e-6}
        result1 = simulator.run_simulation(params1)
        
        # Second simulation with different parameters
        params2 = {'Vi': 24.0, 'Lo': 25e-6}  # Different Lo value
        result2 = simulator.run_simulation(params2)
        
        # Verify both simulations were run
        assert simulator.server.run_sim_with_datastream.call_count == 2
        assert mock_cache.cache_result.call_count == 2
        
        # Verify different parameters were set
        assert simulator.server.load_modelvars.call_count == 2
        
        # Get the parameters for each call
        call1_params = simulator.server.load_modelvars.call_args_list[0][0][0]
        call2_params = simulator.server.load_modelvars.call_args_list[1][0][0]
        
        assert call1_params['Lo'] != call2_params['Lo'], "Parameters should be different"
    
    def test_plecs_file_change_triggers_new_simulation(self, temp_cache_dir):
        """Test that changing PLECS file triggers new simulation even with same parameters."""
        # Create test PLECS files
        original_file = temp_cache_dir / "test1.plecs"
        modified_file = temp_cache_dir / "test2.plecs"
        
        # Create simple PLECS content
        plecs_content1 = """
        Plecs {
          Name "test1"
          InitializationCommands "Vi = 24;"
        }
        """
        plecs_content2 = """
        Plecs {
          Name "test2" 
          InitializationCommands "Vi = 24; Lo = 15e-6;"
        }
        """
        
        original_file.write_text(plecs_content1)
        modified_file.write_text(plecs_content2)
        
        # Create real cache instance
        cache = SimulationCache()
        
        # Same parameters, different files
        params = {'Vi': 24.0, '_simulation_type': 'real_plecs'}
        
        # Simulate results for both files
        timeseries1 = pd.DataFrame({'Time': [1, 2], 'Signal': [0.1, 0.2]})
        metadata1 = {'file': str(original_file)}
        timeseries2 = pd.DataFrame({'Time': [3, 4], 'Signal': [0.3, 0.4]})
        metadata2 = {'file': str(modified_file)}
        
        # Cache result for first file
        cache.cache_result(str(original_file), params, timeseries1, metadata1)
        
        # Try to get cached result for second file (should be None - cache miss)
        cached_result = cache.get_cached_result(str(modified_file), params)
        assert cached_result is None, "Different PLECS files should not share cache"
        
        # Cache result for second file
        cache.cache_result(str(modified_file), params, timeseries2, metadata2)
        
        # Verify both files have separate cache entries
        cached1 = cache.get_cached_result(str(original_file), params)
        cached2 = cache.get_cached_result(str(modified_file), params)
        
        assert cached1 is not None, "Original file cache missing"
        assert cached2 is not None, "Modified file cache missing"
        # Compare metadata to verify they're different cache entries
        assert cached1['metadata'] != cached2['metadata'], (
            "Different files should have different cached results"
        )


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
